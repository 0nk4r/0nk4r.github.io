---
title: "Modelling complex traits with ancestral recombination graphs"
author:
  name: Hanbin Lee
  affiliation: "University of Michigan, Ann Arbor"
  email: "hblee@umich.edu"
venue: "Probabilistic Modelling in Genomics 2025"
date: "07 March 2025"
date-format: "MMM D, YYYY"
bibliography: ref.bib
format: 
  revealjs:
    css: style.css
    slide-number: c/t
    width: 1600
    height: 900
    html-math-method: mathjax
    theme: white
    transition: slide
    navigation-mode: grid
    template-partials:
      - title-slide.html
---

# Overview

::: {.incremental}
- We condition on the sample's ancestral recombination graph (ARG) 
- The full feature of the ARG is superfluous, only the local trees matter $\mathcal{T} = (\mathbf{V}, \mathbf{E})$
<p align="center">
	<img src="imgs/local_trees.svg" width="100%">
</p>	

- Drift and recombination are fixed, so mutation is the sole driver of genetic variability
$$
\mathbf{y} \mid \mathcal{T} \; \sim \; ?
$$
:::

::: footer
Figure from [tskit docs](https://tskit.dev/tutorials/what_is.html)
:::

## The duality between sites and branches

::: {.r-stack}

::: {.fragment .fade-in-then-out .center}
Evolutionary statistics are computed from observed mutations

These are the *site* statistics based on *realized* mutations
:::

::: {.fragment .fade-in-then-out .center}
Branch statistics treat mutations as random 

They *average* over all possible realizations including the observed one given $\mathcal{T}$
:::

::: {.fragment .center}
![](imgs/diversity.jpeg){fig-align="center" height=500}

Can we adapt this *branch* thinking to complex traits?
:::

:::

::: footer
Figure from [@Ralph2020]
:::



# Setup and derivation


::: {.fragment}
The trait $\mathbf{y}$ is a linear function of the genotype $\mathbf{G}$
$$
\mathbf{y} = \mathbf{G}\boldsymbol{\beta} + \boldsymbol{\varepsilon}
$$
$\mathbf{y} \in \mathbb{R}^N$, $\mathbf{G} \in \mathbb{R}^{N \times P}$, 
$\boldsymbol{\beta} \in \mathbb{R}^P$, and $\boldsymbol{\varepsilon} \in \mathbb{R}^N$
:::

::: {.incremental}
- $N \ll P$, it's impossible to fit a high-dimensional regression without additional assumptions
- Perfect collinearity of some columns in $\mathbf{G}$, or perfect linkage disequilibrium (LD)
- A population genetic solution: group variants into branches
:::

## How do we get traits? 

:::: {.columns}

::: {.column width="50%"}

::: {.r-stack}

::: {.fragment .fade-in-then-out}
![](imgs/tree-0.svg){fig-align="center" height=600}
$\mathbf{y}_1=\boldsymbol{\beta}_1+\boldsymbol{\beta}_2$, 
$\mathbf{y}_2 = \boldsymbol{\beta}_2$, $\ldots$
:::

::: {.fragment}
![](imgs/tree-1.svg){fig-align="center" height=600}
$\mathbf{y}_1=\boldsymbol{\beta}_4$, 
$\mathbf{y}_2=\boldsymbol{\beta}_4$, $\ldots$
:::

:::

:::


::: {.column width="50%" .center}

::: {.fragment}
We get trait values by adding up effect sizes ($\boldsymbol{\beta}$)
:::

::: {.fragment}
Sites are different for different realizations

::: {.incremental}
- $\mathbf{y}_n = \mathbf{G}_{n1} \boldsymbol{\beta}_1 + \mathbf{G}_{n2} \boldsymbol{\beta}_2$
- $\mathbf{y}_n = \mathbf{G}_{n3} \boldsymbol{\beta}_3 + \mathbf{G}_{n4} \boldsymbol{\beta}_4$
:::

:::

::: {.fragment}
Can we do something similar with branches?
:::

:::


::::

## Branch-centric view of trait transmission

:::: {.columns}

::: {.column width="50%"}

::: {.r-stack}

::: {.fragment fragment-index=1}
![](imgs/tree-branch.svg){fig-align="center" height=600}
:::

::: {.fragment .fade-in-then-out fragment-index=5}
![](imgs/tree-0.svg){fig-align="center" height=600}
:::

::: {.fragment fragment-index=6}
![](imgs/tree-1.svg){fig-align="center" height=600}
:::

:::

:::


::: {.column width="50%"}

::: {.fragment fragment-index=2}
To inherit a mutation, one should inherit a branch first

:::


::: {.fragment fragment-index=4}
Next, mutations should occur on the branches
:::


:::


::::

## Get a branch, then a mutation



# Ancestral recombination graph linear mixed model (ARG-LMM)

::: {.fragment}
Split $\boldsymbol{\upsilon}$ to $\mathbf{u} = \boldsymbol{\upsilon} - \mathrm{E}\boldsymbol{\upsilon}$ and $\mathbf{f}= \mathrm{E}\boldsymbol{\upsilon}$
$$
\mathbf{y} = \mathbf{Z} \mathbf{u} + \mathbf{Z} \mathbf{f} + \boldsymbol{\varepsilon}
$$
:::

::: {.fragment}
This is the ancestral recombination graph linear mixed model (ARG-LMM)
:::

::: {.incremental}
- The random effects are tied to a physical process - Mutations!
- Their properties can be deduced from the mutational process
- We don't *assume* but *derive* the model
:::

::: {.fragment}
Let's characterize $\mathbf{u}$ (the random effects) and $\mathbf{f}$ (the fixed effects)
:::



# $\textsf{tslmm}$, fitting ARG-LMM to tree sequences

::: {.incremental}
- $\textsf{tslmm}$ utilizes an efficient *genetic relatedness matrix - vector product* to fit the restricted maximum likelihood (REML) objective
- Assumes
$$
	\frac{1}{s_e} \sum_{p: p \in e} \boldsymbol{\beta}^2 u_{ep} = \tau_e^2 = \tau^2
$$
for all edges $e \in \mathbf{E}$.
- Approximately true provided the edge is long enough


:::

## Runtime

![](imgs/runtime.svg){.fragment fig-align="center" height="700"}

::: {.fragment}
The runtime scales linearly with respect to the number of individuals
:::

## Estimation

:::{.r-stack}

:::{.fragment .fade-in-then-out}
**Simulated trees**

![](imgs/estimation_true.svg){height="700"}
:::

:::{.fragment .fade-in-then-out}
**Inferred (tsinfer+tsdate) trees**

![](imgs/estimation_infer.svg){height="700"}
:::

:::


## Best linear unbiased prediction (BLUP)

![](imgs/prediction.svg){.fragment fig-align="center" height="700"}

::: {.fragment}
True trees are better, but inferred trees are not too behind!
:::


# Complex traits through the lens of ARG-LMM

$$
\text{What does ARG-LMM tell us about complex trait analysis?}
$$

## Polygenic prediction

::: {.incremental}
- All individuals have different amount of genetic variance (except haploids)
$$
	\mathrm{Var}(h_{n1}+h_{n2}) = \mathrm{Var}(h_{n1}) + \mathrm{Var}(h_{n2}) + \textcolor{red}{2\mathrm{Cov}(h_{n1},h_{n2})}
$$

- $\textcolor{red}{\mathrm{Cov}(h_{n1},h_{n2})}$ is the shared amount of area between the two haplotypes of an individual

:::


![](imgs/geneticvariance.svg){.fragment fig-align="center" height="400"}

::: {.r-stack}

::: {.fragment .fade-in-then-out}
Some people are more genetically variable than others
:::

::: {.fragment .fade-in-then-out}
Some people are more easy to predict genetically than others
:::

::: {.fragment .fade-in-then-out}
Some populations are inherently harder to predict!
:::

:::

## *Missing* heritability?

::: {.fragment}
No single quantity can summarize the relative contribution of genetics to trait variance
:::
::: {.incremental}
- The notion of heritability is ill-defined once you conditioned on the ARG
- This applies to SNP-based LMM heritability if one think of ARG-LMM as the underlying model
:::

::: {.fragment}
Even in haploids, ARG-LMM variance component only reflects mutational variability
:::
::: {.incremental}
- Pedigree-based heritability captures Mendelian segregation
- Various evolutionary processes are absent in ARG-LMM's generative model
- Why compare quantities stemming from different random forces?
:::

![](https://whalebonemag.com/wp-content/uploads/2022/11/applesandoranges-lilguys-02.jpg){.fragment height=250 fig-align="center"}

::: footer
Figure from [Whalebone Magazine](https://whalebonemag.com/)
:::




## Becareful of pseudoreplication

::: {.incremental}
- Non-overlapping samples are not independent
- Everyone shares some amount of mutational history
- Parameter estimates (e.g. variance components) are correlated
:::

![](imgs/pseudoreplication.svg){.fragment fig-align="center" height="400"}

::: {.r-stack}

::: {.fragment .fade-in-then-out}
This is also the very reason why BLUP works
:::

::: {.fragment}
We are all correlated!
:::

:::



# Thank you for listening

Collaborators: Nathaniel Pope (Oregon), Jerome Kelleher (Oxford), Gregor Gorjanc (Edinburgh), and Peter Ralph (Oregon)


## References

::: {#refs}
:::

# Technical Notes

## Edge splitting

::: {.incremental}
- Nodes and edges are reused across multiple trees in a tree sequence
- Edges, in particular, may not have a unique set of samples along their span
- Salehi Nowbandegani and colleagues *bricked* the edges to divide them [@SalehiNowbandegani2023]
- Henceforth, we assume that edges are splitted to have a unique subtopology
$$
\mathbf{Z}_{ne} = \text{The number of haplotypes of individual $n$ that inherit $e$} 
$$
The overall matrix $\mathbf{Z}$ is an individual-edge design matrix.
:::


## Collapsing variants to edges

::: {.incremental}
- When does an individual possess a derived allele? ($\text{ancestral}=0$, $\text{derived}=1$)
- Let $\mathbf{1}_{ep}$ be the indicator *random* variable of a mutation at edge $e$ and position $p$
:::

<center>
::: {.fragment}
An individual should be a descendant of an edge ($\mathbf{Z}_{ne}=1$)
:::

::: {.fragment}
$$
+
$$
That edge should have mutation ($\mathbf{1}_{ep}=1$)
:::
</center>

::: {.fragment}
$$
\mathbf{G}_{np} = \sum_{e: p \in e} \mathbf{Z}_{ne} \mathbf{1}_{ep} \quad \Leftrightarrow \quad \mathbf{G}_p = \sum_{e:p \in e} \mathbf{Z}_{e} \mathbf{1}_{ep}
$$
:::
::: {.incremental}
- Assumes that there are no parent-child mutation pairs, but allows *some* recurrent mutations
:::


## Exchange the summations

::: {.fragment}
Recall $\mathbf{G}_p = \sum_{e:p \in e} \mathbf{Z}_{e} \mathbf{1}_{ep}$
and $\mathbf{y} = \sum_{p=1}^P \mathbf{G}_p \boldsymbol{\beta}_p + \boldsymbol{\varepsilon}$
:::

:::{.r-stack}


::: {.fragment .fade-in-then-out}
Substitute $\mathbf{G}_p$
$$
\textcolor{red}{\sum_{p=1}^P \sum_{e:p \in e}} \mathbf{Z}_e \boldsymbol{\beta}_p \mathbf{1}_{ep} + \boldsymbol{\varepsilon}
$$
:::

::: {.fragment .fade-in-then-out}
Exchange the inner and the outer summation
$$
\textcolor{red}{\sum_{e=1}^E \sum_{p:p \in e}} \mathbf{Z}_e \boldsymbol{\beta}_p \mathbf{1}_{ep} + \boldsymbol{\varepsilon} 
$$
:::

::: {.fragment}
Pull out $\mathbf{Z}_e$ and group the positions nested in $p: p \in e$
$$
\begin{aligned}
	& \sum_{e=1}^E \mathbf{Z}_e \textcolor{blue}{\left(\sum_{p:p\in e} \boldsymbol{\beta}_p \mathbf{1}_{ep} \right)} + \boldsymbol{\varepsilon} \\
	&= \sum_{e=1}^E \mathbf{Z}_e \textcolor{blue}{\boldsymbol{\upsilon}_e} + \boldsymbol{\varepsilon} \\
	&= \mathbf{Z} \boldsymbol{\upsilon} + \boldsymbol{\varepsilon}
\end{aligned}
$$
:::
:::

::: {.fragment}
$\boldsymbol{\upsilon}$ is a random variable made up of mutation-driven random variables $\mathbf{1}_{ep}$!
:::

## Random effects are independent

::: {.incremental}
- Independent entries of random effects is a key assumption of linear mixed models
- This can be *proved* in ARG-LMM, instead of assuming it
$$
	\mathrm{Cov}( \mathbf{u}_e, \mathbf{u}_{e'} ) = \sum_{p \in e,e'} \boldsymbol{\beta}_p^2 \mathrm{Cov}(\mathbf{1}_{ep}, \mathbf{1}_{e'p})
$$

- The covariance between the indicators are higher-order terms of mutation rates, so we ignore it [@Wakeley2008]
$$
	\begin{aligned}
	\mathrm{Cov}(\mathbf{1}_{ep}, \mathbf{1}_{e'p}) &= \mathrm{E}[\mathbf{1}_{ep}\mathbf{1}_{e'p}] - \mathrm{E}[\mathbf{1}_{e'p}]\mathrm{E}[\mathbf{1}_{ep}] \\
		&= 0 -l_eu_{ep}l_{e'}u_{e'p} \approx 0
	\end{aligned}
$$
where $l_e$ is the (time-)length of edge $e$.

:::


## The marginal distribution of $\mathbf{u}_e$?

::: {.incremental}
- The Gaussian prior on random effects is a popular choice
- One might be tempted to invoke the central limit theorem to $\mathbf{u}_e$ (sum of indicators)
	$$
		\mathbf{u}_e \bigg/ \sqrt{l_e s_e} \cdot \sqrt{ \frac{1}{s_e} \sum_{p:p \in e} \boldsymbol{\beta}_p^2 u_{ep} } 
		\rightarrow N(0,1^2) \text{ as } s_e \rightarrow \infty
	$$
	where $s_e$ is the span (in base pairs) of edge $e$

- The convergence is unlikely to be fast enough given the small value of $\mathbf{E}[\mathbf{1}_{ep}]$ (Berry-Esseen).

- Fortunately, the variance is computable and is 
	$$
		\mathrm{Var}(\mathbf{u}_e) = l_e s_e \cdot \frac{1}{s_e} \sum_{p:p \in e} \boldsymbol{\beta}_p^2 u_{ep}
	$$
:::

## More on $\mathrm{Var}(\mathbf{u}_e)$

::: {.incremental}
- The weight $\mathrm{Var}(\mathbf{u}_e)$ has two components
- The area $l_e s_e$ 
- Mutation rate-weighted squared average of effect sizes
	$$
		\tau_e^2 = \frac{1}{s_e} \sum_{p:p \in e} \boldsymbol{\beta}_p^2 u_{ep}
	$$
- As a measure of functional significance, variance components are confounded by the area
:::

## Fixed effects are constant under neutrality

::: {.incremental}

- Suppose that $u_{ep}=u_p$, i.e., the mutation rate is constant across edges for a given position
:::

::: {.r-stack}

::: {.fragment .fade-in-then-out}
$$
\begin{aligned}
	&\left[ \mathbf{Z} \mathbf{f} \right]_n = \sum_{e=1}^E \mathbf{Z}_{ne} \mathbf{E}
	\left[ \sum_{p: p \in e} \boldsymbol{\beta}_p\mathbf{1}_{ep} \right] \\
	\end{aligned}
$$
:::

::: {.fragment}
$$
\sum_{p=1}^P \boldsymbol{\beta}_p u_p 
	\left(
			\sum_{e: p \in e} \mathbf{Z}_{ne} l_e
	\right)
	= \sum_{p=1}^P \boldsymbol{\beta}u_p \cdot 2t_{\mathrm{root},p} = \text{const. resp. to $n$}
$$
:::

:::

::: {.incremental}
- An intercept is enough to account for the fixed effects $\mathbf{Z}\mathbf{f}$ under this condition

- The assumption is standard in neutral settings
:::
::: {.fragment}
$$
	\text{\textcolor{red}{Conjecture:} selection $\Rightarrow$ fixed effects?}
$$
:::




